/**********************************************************************
**
** This file is part of ANGLECORE, an open-source software development
** kit for audio plugins.
**
** ANGLECORE is free software: you can redistribute it and / or modify
** it under the terms of the GNU General Public License as published by
** the Free Software Foundation, either version 3 of the License, or
** (at your option) any later version.
**
** ANGLECORE is distributed in the hope that it will be useful,
** but WITHOUT ANY WARRANTY; without even the implied warranty of
** MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.See the
** GNU General Public License for more details.
**
** You should have received a copy of the GNU General Public License
** along with ANGLECORE.If not, see <https://www.gnu.org/licenses/>.
**
** Copyright(C) 2020, ANGLE
**
**********************************************************************/

#pragma once

#include <memory>
#include <mutex>
#include <thread>
#include <chrono>
#include <utility>

#include "../audioworkflow/AudioWorkflow.h"
#include "../renderer/Renderer.h"
#include "MIDIBuffer.h"
#include "../audioworkflow/instrument/Instrument.h"
#include "../../config/RenderingConfig.h"
#include "../../config/AudioConfig.h"

namespace ANGLECORE
{
    /**
    * \class Master Master.h
    * Agent that orchestrates the rendering and the interaction with the end-user
    * requests. It should be the only entry point from outside when developping an
    * ANGLECORE-based application.
    */
    class Master
    {
    public:
        Master();

        /**
        * Sets the sample rate of the Master's AudioWorkflow.
        * @param[in] sampleRate The value of the sample rate, in Hz.
        */
        void setSampleRate(floating_type sampleRate);

        /**
        * Clears the Master's internal MIDIBuffer to prepare for rendering the next
        * audio block.
        */
        void clearMIDIBufferForNextAudioBlock();

        /**
        * Adds a new MIDIMessage at the end of the Master's internal MIDIBuffer, and
        * returns a reference to it. This method should only be called by the
        * real-time thread, right before calling the renderNextAudioBlock() method.
        */
        MIDIMessage& pushBackNewMIDIMessage();

        /**
        * Renders the next audio block, using the internal MIDIBuffer as a source
        * of MIDI messages, and the provided parameters for computing and exporting
        * the output result.
        * @param[in] audioBlockToGenerate The memory location that will be used to
        *   output the audio data generated by the Renderer. This should correspond
        *   to an audio buffer of at least \p numChannels audio channels and \p
        *   numSamples audio samples.
        * @param[in] numChannels The number of channels available at the memory
        *   location \p audioBlockToGenerate. Note that ANGLECORE's engine may
        *   generate more channels than this number, and eventually merge them all
        *   to match that number.
        * @param[in] numSamples The number of samples to generate and write into
        *   \p audioBlockToGenerate.
        */
        void renderNextAudioBlock(float** audioBlockToGenerate, unsigned short numChannels, uint32_t numSamples);

        template<class InstrumentType>
        bool addInstrument();

    protected:

        /** Processes the given MIDIMessage. */
        void processMIDIMessage(const MIDIMessage& message);

    private:
        AudioWorkflow m_audioWorkflow;
        Renderer m_renderer;
        MIDIBuffer m_midiBuffer;
    };

    template<class InstrumentType>
    bool Master::addInstrument()
    {
        std::lock_guard<std::mutex> scopedLock(m_audioWorkflow.getLock());

        /* Can we insert a new instrument? We need to find an empty spot first */
        unsigned short emptyRackNumber = m_audioWorkflow.findEmptyRack();
        if (emptyRackNumber >= ANGLECORE_MAX_NUM_INSTRUMENTS_PER_VOICE)

            /*
            * There is no empty spot, so we stop here and return false. We cannot
            * insert a new instrument to the workflow.
            */
            return false;

        /*
        * Otherwise, if we can insert a new instrument, then we need to prepare the
        * instrument's environment, as well as a new ConnectionRequest for bridging
        * the instrument with the real-time rendering pipeline.
        */

        std::shared_ptr<ConnectionRequest> request = std::make_shared<ConnectionRequest>();
        ConnectionPlan& plan = request->plan;

        for (unsigned short v = 0; v < ANGLECORE_NUM_VOICES; v++)
        {
            /*
            * We create an Instrument of the given type, and then cast it to an
            * Instrument, to ensure type validity.
            */
            std::shared_ptr<Instrument> instrument = std::make_shared<InstrumentType>();

            /*
            * Then, we insert the Instrument into the Workflow and plan its bridging
            * to the real-time rendering pipeline.
            */
            m_audioWorkflow.addInstrumentAndPlanBridging(v, emptyRackNumber, instrument, plan);
        }

        /*
        * Once here, we have a ConnectionPlan ready to be used in our
        * ConnectionRequest. We now need to precompute the consequences of executing
        * than plan and connecting all of the instruments to the AudioWorkflow's
        * real-time rendering pipeline.
        */

        /*
        * We first calculate the rendering sequence that will take effect right
        * after the plan is executed.
        */
        std::vector<std::shared_ptr<Worker>> newRenderingSequence = m_audioWorkflow.buildRenderingSequence(plan);

        /*
        * And from that sequence, we can precompute and assign the rest of the
        * request properties:
        */
        request->newRenderingSequence = newRenderingSequence;
        request->newVoiceAssignments = m_audioWorkflow.getVoiceAssignments(newRenderingSequence);
        request->oneIncrements.resize(newRenderingSequence.size(), 1);

        /*
        * Finally, we need to send the ConnectionRequest to the Renderer. To avoid
        * any memory deallocation by the real-time thread after it is done with the
        * request, we do not pass the request straight to the Renderer. Instead, we
        * create a copy and send that copy to the latter. Therefore, when the
        * Renderer is done with the request, it will only delete a copy of a shared
        * pointer and decrement its reference count by one, signaling to the Master
        * the request has been processed (and either succeeded or failed), and that
        * it can be safely destroyed by the non real-time thread that created it.
        */

        /* We copy the ConnectionRequest... */
        std::shared_ptr<ConnectionRequest> requestCopy = request;

        /* ... And post the copy:*/
        m_renderer.postConnectionRequest(std::move(requestCopy));

        /*
        * From now on, the ConnectionRequest is in the hands of the real-time
        * thread. We cannot access any member of 'request' except the atomic boolean
        * 'hasBeenSuccessfullyProcessed'. We will still use the reference count of
        * the shared pointer as an indicator of when the real-time thread is done
        * with the request (although it is not guaranteed to be safe by the
        * standard). As long as that number is greater than 1 (and, normally, equal
        * to 2), the real-time thread is still in possession of the copy, and
        * possibly processing it. So the non real-time thread should wait. When this
        * number reaches one, it means the real-time thread is done with the request
        * and the non real-time thread can safely delete it. 
        */

        /*
        * To avoid infinite loops and therefore deadlocks while waiting for the
        * real-time thread, we introduce a timeout, using a number of attempts.
        */
        const unsigned short timeoutAttempts = 4;
        unsigned short attempt = 0;

        /*
        * We then wait for the real-time thread to finish, or for the timeout to
        * arise.
        */
        while (request.use_count() > 1 && attempt++ < timeoutAttempts)
            std::this_thread::sleep_for(std::chrono::milliseconds(20));

        /*
        * Once here, we either reached the timeout, or the copy of the
        * ConnectionRequest has been destroyed, and only the original remains, and
        * can be safely deleted. In any case, the original request will be deleted,
        * so if the timeout is the reason for leaving the loop, then the copy will
        * outlive the original in the real-time thread, which will trigger memory
        * deallocation upon destruction, and possibly provoke an audio glitch (this
        * should actually be very rare). If we left the loop because the copy was
        * destroyed (which is the common case), then the original will be safely
        * deleted here by the non real-time thread.
        */

        /*
        * We access the 'hasBeenSuccessfullyProcessed' variable that may have been
        * edited by the real-time thread, in order to determine whether or not the
        * request was been successfully processed.
        */
        return request->hasBeenSuccessfullyProcessed.load();
    }
}